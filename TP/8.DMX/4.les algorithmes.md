# üî® MINING STRUCTURES & 9 ALGORITHMES
## Configuration et Interpr√©tation des Scores

---

## üìã LES 9 ALGORITHMES MICROSOFT

```
1. Decision Trees        ‚Üí Classification/R√©gression (interpr√©table)
2. Clustering            ‚Üí Segmentation automatique
3. Na√Øve Bayes          ‚Üí Classification rapide (probabilit√©s)
4. Neural Network       ‚Üí Classification/R√©gression (pr√©cis mais opaque)
5. Logistic Regression  ‚Üí Probabilit√© binaire (0-1)
6. Association Rules    ‚Üí Market Basket (produits ensemble)
7. Time Series          ‚Üí Pr√©visions temporelles
8. Sequence Clustering  ‚Üí Parcours clients
9. Linear Regression    ‚Üí Pr√©diction valeur continue
```

---

## üéØ CAS 1 : CHURN PREDICTION

### **Structure 1A : Decision Trees**

**Quand l'utiliser :**  
- Besoin de comprendre POURQUOI un client va churner
- Pr√©senter r√©sultats √† direction (arbre lisible)
- Identifier facteurs cl√©s

**Cr√©ation dans SSAS :**

```
Mining Structures > New Mining Structure

1. Selection Method: From existing relational database
2. Data Source: DW_Shoes_Mining
3. Mining Technique: Microsoft Decision Trees

4. Select Case Table: vw_ChurnPrediction_Features
   Key: CustomerKey

5. Colonnes:
   INPUT:
   ‚òë RecencyScore (Discretized - Already 1-5)
   ‚òë FrequencyScore (Discretized - Already 1-5)
   ‚òë MonetaryScore (Discretized - Already 1-5)
   ‚òë TenureScore (Discretized - Already 1-5)
   ‚òë AgeGroup (Discrete)
   ‚òë Gender (Discrete)
   ‚òë IncomeGroup (Discrete)
   ‚òë PurchaseTrend (Discrete)
   ‚òë AvgDaysBetweenOrders (Continuous ‚Üí Discretize 5 buckets)
   ‚òë FavoriteCategory (Discrete)
   
   PREDICTABLE:
   ‚òë HasChurned (Discrete: 0 or 1) ‚Üê LE LABEL!

6. Split data:
   Training: 70%
   Testing: 30%

7. Structure name: Churn_DecisionTree
   Model name: DT_Churn_Model
```

**Param√®tres algorithme (Algorithm Parameters) :**

```
COMPLEXITY_PENALTY: 0.5     (D√©faut, √©quilibre pr√©cision/simplicit√©)
MINIMUM_SUPPORT: 10         (Min 10 cas pour cr√©er split)
SCORE_METHOD: 4             (Entropy - meilleur pour binaire)
SPLIT_METHOD: 3             (Both splits)
```

**Traitement :**

```
Clic droit sur structure > Process
‚Üí Process Full
‚Üí Run
‚Üí Attendre fin (1-2 min)
```

**Interpr√©ter les SCORES :**

```
Mining Model Viewer > Decision Tree tab

Arbre visuel:
Root Node: All Cases (500 clients)
‚îú‚îÄ RecencyScore <= 2 (250 clients) ‚Üí 92% CHURN ‚ö†Ô∏è
‚îÇ  ‚îî‚îÄ FrequencyScore <= 2 (180 clients) ‚Üí 98% CHURN ‚ö†Ô∏è‚ö†Ô∏è
‚îÇ      ‚Üí ACTION: Campagne urgente!
‚îÇ
‚îî‚îÄ RecencyScore > 2 (250 clients) ‚Üí 12% CHURN ‚úì
   ‚îî‚îÄ MonetaryScore >= 4 (120 clients) ‚Üí 3% CHURN ‚úì‚úì
       ‚Üí VIP, pas d'action

Dependency Network:
- RecencyScore ‚Üí FORTE influence (ligne √©paisse)
- FrequencyScore ‚Üí FORTE influence
- AgeGroup ‚Üí Faible influence (ligne fine)
```

**Requ√™te DMX pour scorer nouveaux clients :**

```dmx
-- Pr√©dire HasChurned + Probabilit√©
SELECT 
  t.CustomerKey,
  PredictProbability([DT_Churn_Model].[HasChurned], 1) AS ChurnProbability,
  Predict([DT_Churn_Model].[HasChurned]) AS PredictedChurn
FROM [DT_Churn_Model]
PREDICTION JOIN
  OPENQUERY([DW_Shoes_Mining],
    'SELECT * FROM vw_ChurnPrediction_Features'
  ) AS t
ON 
  [DT_Churn_Model].[RecencyScore] = t.RecencyScore AND
  [DT_Churn_Model].[FrequencyScore] = t.FrequencyScore AND
  [DT_Churn_Model].[MonetaryScore] = t.MonetaryScore

/* R√âSULTAT:
CustomerKey  ChurnProbability  PredictedChurn
CUST-00001   0.03              0              ‚Üê VIP, safe
CUST-00002   0.87              1              ‚Üê HIGH RISK!
CUST-00003   0.42              0              ‚Üê Medium risk

INTERPR√âTATION SCORE:
0.00-0.20 = Vert (safe)
0.21-0.50 = Orange (surveiller)
0.51-0.80 = Rouge (action n√©cessaire)
0.81-1.00 = Rouge fonc√© (urgence!)
*/
```

---

### **Structure 1B : Logistic Regression**

**Quand l'utiliser :**  
- Besoin de score probabilit√© pr√©cis (0.0 √† 1.0)
- Classification binaire pure
- Plus rapide que Neural Network

**Cr√©ation :**

```
M√™me structure, nouvel algorithme:
Clic droit Mining Structure > New Mining Model
Algorithm: Microsoft Logistic Regression
Name: LR_Churn_Model
```

**Param√®tres :**

```
MAXIMUM_INPUT_ATTRIBUTES: 255
MAXIMUM_OUTPUT_ATTRIBUTES: 255
MAXIMUM_STATES: 100
(Laisser d√©fauts)
```

**Interpr√©ter les SCORES :**

```
Mining Model Viewer > Neural Network tab

Attribute Profiles:
Feature         Impact on Churn=1
RecencyScore=1  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (0.92)  ‚Üê Si score 1 ‚Üí 92% churn
RecencyScore=5  ‚ñà‚ñà (0.05)            ‚Üê Si score 5 ‚Üí 5% churn
FrequencyScore=1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (0.88)
MonetaryScore=1  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (0.75)

Attribute Discrimination (Churn=1 vs Churn=0):
RecencyScore    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Strongly favors Churn=1
FrequencyScore  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Strongly favors Churn=1
TenureScore     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Moderately favors Churn=1
AgeGroup        ‚ñà‚ñà Slightly favors Churn=1
```

**Requ√™te DMX :**

```dmx
SELECT 
  t.CustomerKey,
  PredictProbability([LR_Churn_Model].[HasChurned], 1) AS ChurnScore
FROM [LR_Churn_Model]
PREDICTION JOIN
  OPENQUERY([DW_Shoes_Mining],
    'SELECT * FROM vw_ChurnPrediction_Features WHERE CustomerKey = 123'
  ) AS t
ON ...

/* SCORE = Probabilit√© exacte (plus pr√©cis que Decision Tree)
Utiliser pour:
- Scoring batch de clients
- Ranking (top 100 clients √† risque)
- Seuils d√©cision (ex: score > 0.6 ‚Üí action)
*/
```

---

### **Structure 1C : Neural Network**

**Quand l'utiliser :**  
- Besoin de pr√©cision maximale
- Relations complexes non-lin√©aires
- Peu important de comprendre le "pourquoi"

**Cr√©ation :**

```
Algorithm: Microsoft Neural Network
Name: NN_Churn_Model

Param√®tres:
HIDDEN_NODE_RATIO: 4         (4x n≈ìuds cach√©s vs inputs)
HOLDOUT_PERCENTAGE: 30       (30% test)
MAXIMUM_INPUT_ATTRIBUTES: 20
MAXIMUM_OUTPUT_ATTRIBUTES: 1
SAMPLE_SIZE: 10000
```

**Interpr√©ter les SCORES :**

```
Mining Accuracy Chart > Lift Chart

Comparer 3 mod√®les:
Decision Tree:   Lift = 2.8 (280% meilleur que random)
Logistic Reg:    Lift = 3.1
Neural Network:  Lift = 3.4 ‚Üê Plus pr√©cis!

Score Distribution:
0.0-0.1:  50 clients (2% churn r√©el)
0.1-0.3:  80 clients (12% churn)
0.3-0.5:  70 clients (35% churn)
0.5-0.7:  120 clients (68% churn) ‚Üê Seuil action
0.7-1.0:  180 clients (91% churn) ‚Üê Urgence!

‚Üí Fixer seuil √† 0.5 = Capture 68%+ des vrais churn√©s
```

**Requ√™te DMX :**

```dmx
-- Top 50 clients √† plus haut risque
SELECT TOP 50
  t.CustomerKey,
  t.CustomerName,
  PredictProbability([NN_Churn_Model].[HasChurned], 1) AS RiskScore
FROM [NN_Churn_Model]
PREDICTION JOIN
  OPENQUERY([DW_Shoes_Mining],
    'SELECT * FROM DimCustomer WHERE HasChurned = 0'  -- Clients actifs
  ) AS t
ON ...
ORDER BY RiskScore DESC;

/* ACTION BUSINESS:
Top 10:  Appel t√©l√©phone + offre 30%
Top 50:  Email personnalis√© + 20%
Top 100: Newsletter g√©n√©rique
*/
```

---

## üéØ CAS 2 : SEGMENTATION CLIENTS

### **Structure 2 : Clustering**

**Quand l'utiliser :**  
- D√©couvrir segments naturels (sans labels pr√©existants)
- Comprendre profils clients
- Personnaliser marketing

**Cr√©ation :**

```
Mining Structure > New
Algorithm: Microsoft Clustering

Colonnes:
INPUT (pas de PREDICTABLE!):
‚òë RecencyScore
‚òë FrequencyScore
‚òë MonetaryScore
‚òë TenureScore
‚òë AgeGroup
‚òë IncomeGroup
‚òë AvgDaysBetweenOrders

Param√®tres:
CLUSTER_COUNT: 0            (Auto-d√©tection)
CLUSTERING_METHOD: 1        (EM algorithm)
MINIMUM_SUPPORT: 1
MODELLING_CARDINALITY: 10
```

**Interpr√©ter les SCORES :**

```
Viewer > Cluster Diagram

5 Clusters d√©tect√©s automatiquement:

Cluster 1 (n=120): "VIP Fid√®les" ‚≠ê‚≠ê‚≠ê
- RecencyScore: 4.8 (tr√®s r√©cent)
- FrequencyScore: 4.9 (tr√®s fr√©quent)
- MonetaryScore: 4.7 (gros d√©penseurs)
- TenureScore: 4.5 (anciens)
‚Üí Churn: 2%
‚Üí ACTION: Programme VIP, avant-premi√®res

Cluster 2 (n=150): "R√©guliers Stables" ‚≠ê‚≠ê
- RecencyScore: 3.8
- FrequencyScore: 3.5
- MonetaryScore: 3.2
‚Üí Churn: 15%
‚Üí ACTION: Fid√©lisation, challenges

Cluster 3 (n=80): "Occasionnels √† Potentiel" ‚≠ê
- RecencyScore: 3.0
- FrequencyScore: 2.1
- MonetaryScore: 2.8
- IncomeGroup: High (!)  ‚Üê Ont les moyens!
‚Üí Churn: 35%
‚Üí ACTION: Up-sell, premium collection

Cluster 4 (n=100): "Dormants" ‚ö†Ô∏è
- RecencyScore: 1.2 (inactifs!)
- FrequencyScore: 1.8
- MonetaryScore: 1.5
‚Üí Churn: 88%
‚Üí ACTION: Win-back 50%, sinon abandonner

Cluster 5 (n=50): "Nouveaux Testeurs"
- RecencyScore: 4.5 (r√©cent)
- TenureScore: 1.2 (nouveaux!)
- FrequencyScore: 1.0 (1 seul achat)
‚Üí Churn: 45%
‚Üí ACTION: Onboarding, 2√®me achat -15%
```

**Requ√™te DMX :**

```dmx
-- Assigner cluster √† chaque client
SELECT 
  t.CustomerKey,
  Cluster() AS AssignedCluster,
  ClusterProbability() AS ClusterConfidence
FROM [Clustering_Model]
PREDICTION JOIN
  OPENQUERY([DW_Shoes_Mining],
    'SELECT * FROM vw_ChurnPrediction_Features'
  ) AS t
ON ...

/* R√âSULTAT:
CustomerKey  AssignedCluster      ClusterConfidence
CUST-00001   Cluster 1 (VIP)      0.92              ‚Üê Tr√®s confiant
CUST-00002   Cluster 4 (Dormant)  0.88
CUST-00003   Cluster 2 (Regular)  0.65              ‚Üê Moins confiant

UTILISATION:
UPDATE DimCustomer
SET CustomerSegment = ClusterName
WHERE CustomerKey = X
‚Üí Segmentation automatique!
*/
```

---

## üéØ CAS 3 : MARKET BASKET

### **Structure 3 : Association Rules**

**Quand l'utiliser :**  
- "Clients qui ach√®tent X ach√®tent aussi Y"
- Recommandations produits
- Cross-sell / Up-sell

**Cr√©ation :**

```
Mining Structure > New
Algorithm: Microsoft Association

Tables:
CASE Table: FactSales
  Key: CustomerKey
  
NESTED Table: Products
  Key: ProductKey
  Input: ProductName (ou Category)

Param√®tres:
MINIMUM_SUPPORT: 0.01       (1% des transactions)
MINIMUM_PROBABILITY: 0.4    (40% confiance minimum)
MAXIMUM_ITEMSET_SIZE: 3     (Max 3 produits ensemble)
```

**Interpr√©ter les SCORES :**

```
Viewer > Rules tab

Rule                                    Probability  Importance
Sport Shoes ‚Üí Sport Socks               0.68         0.85       ‚≠ê‚≠ê‚≠ê
Boots ‚Üí Waterproof Spray                0.72         0.78       ‚≠ê‚≠ê‚≠ê
Formal Shoes ‚Üí Formal Shoes (autre)     0.45         0.62       ‚≠ê‚≠ê
Casual White ‚Üí Casual Black             0.52         0.58       ‚≠ê‚≠ê

EXPLICATION SCORES:
- Probability (Confiance): 
  68% des clients qui ach√®tent Sport Shoes ach√®tent aussi Sport Socks
  
- Importance (Lift):
  0.85 = Forte corr√©lation
  Si >0.5 ‚Üí Association significative
  Si <0.3 ‚Üí Hasard

Itemsets tab:
{Sport Shoes, Sport Socks}              Support: 120 transactions
{Boots, Spray, Socks}                   Support: 45 transactions
```

**Requ√™te DMX :**

```dmx
-- Recommander produits pour un client
SELECT 
  t.ProductKey,
  PredictAssociation([Assoc_Model].[Products], 3) AS Recommendations
FROM [Assoc_Model]
NATURAL PREDICTION JOIN
  (SELECT 'SHOE-S001' AS ProductKey UNION
   SELECT 'SHOE-S005') AS t

/* R√âSULTAT:
Current Basket: Sport Shoes, Trail Shoes
Recommendations:
1. Sport Socks (Prob: 0.68, Importance: 0.85)
2. Running Shorts (Prob: 0.52, Importance: 0.61)
3. Water Bottle (Prob: 0.41, Importance: 0.55)

UTILISATION E-COMMERCE:
"Clients ayant achet√© ces articles ont aussi achet√©..."
*/
```

---

## üéØ CAS 4 : PR√âVISIONS VENTES

### **Structure 4 : Time Series**

**Quand l'utiliser :**  
- Pr√©dire ventes futures
- Planification stock
- D√©tection tendances

**Cr√©ation :**

```
Mining Structure > New
Algorithm: Microsoft Time Series

Table: 
SELECT 
  YEAR(t.FullDate) * 100 + MONTH(t.FullDate) AS YearMonth,
  SUM(s.NetAmount) AS MonthlySales
FROM FactSales s
JOIN DimTime t ON s.TimeKey = t.TimeKey
GROUP BY YEAR(t.FullDate), MONTH(t.FullDate)
ORDER BY YearMonth

Key: YearMonth (Time key)
Predictable: MonthlySales (Continuous)

Param√®tres:
PERIODICITY_HINT: {12}      (Saisonnalit√© annuelle)
FORECAST_METHOD: MIXED      (ARIMA + ARTXP)
HISTORIC_MODEL_GAP: 10      (Ignore 10 premiers mois)
```

**Interpr√©ter les SCORES :**

```
Viewer > Chart tab

Historique (trait bleu):
202201: ‚Ç¨85K
202202: ‚Ç¨78K
...
202412: ‚Ç¨112K

Pr√©dictions (trait orange):
202501: ‚Ç¨95K ¬± ‚Ç¨8K    (Confidence: Bande grise)
202502: ‚Ç¨88K ¬± ‚Ç¨9K
202503: ‚Ç¨102K ¬± ‚Ç¨10K
202504: ‚Ç¨108K ¬± ‚Ç¨11K
...
202512: ‚Ç¨125K ¬± ‚Ç¨15K  ‚Üê D√©cembre (f√™tes)

Deviation:
MAPE (Mean Absolute Percentage Error): 7.2%
‚Üí Erreur moyenne 7% = Mod√®le fiable ‚úì

Si MAPE > 20% ‚Üí Mod√®le peu fiable ‚úó
```

**Requ√™te DMX :**

```dmx
-- Pr√©dire 6 prochains mois
SELECT 
  PredictTimeSeries([TS_Model].[MonthlySales], 6) AS Forecast
FROM [TS_Model]

/* R√âSULTAT:
$TIME        Value     Std Dev
202501       95000     8000
202502       88000     9000
202503       102000    10000
202504       108000    11000
202505       115000    12000
202506       98000     13000

UTILISATION:
- Planifier achats stock
- Ajuster marketing (mois faibles)
- D√©finir objectifs ventes r√©alistes
*/
```

---

## üéØ CAS 5 : PARCOURS CLIENT

### **Structure 5 : Sequence Clustering**

**Quand l'utiliser :**  
- Identifier parcours d'achat typiques
- Optimiser customer journey
- Pr√©dire prochaine action

**Cr√©ation :**

```
Algorithm: Microsoft Sequence Clustering

Tables:
CASE: Customer
NESTED SEQUENCE: Purchases (ordonn√©es par date)

Colonnes sequence:
Key Sequence: OrderDate
Key: ProductCategory
```

**Interpr√©ter les SCORES :**

```
Viewer > State Transitions tab

S√©quences d√©couvertes:

Cluster 1: "New Customer Journey" (n=120)
Sport (1st) ‚Üí Casual (2nd) ‚Üí Sport (3rd)
Probability: 0.68

Cluster 2: "Fashion Journey" (n=80)
Casual ‚Üí Casual (diff style) ‚Üí Formal
Probability: 0.72

Cluster 3: "Seasonal Buyer" (n=60)
Boots (Winter) ‚Üí Casual (Spring) ‚Üí Sport (Summer)
Probability: 0.65

Transition Matrix:
From Sport ‚Üí To Casual: 42%
From Sport ‚Üí To Sport: 35%
From Sport ‚Üí To Formal: 12%
```

**Requ√™te DMX :**

```dmx
-- Pr√©dire prochaine cat√©gorie
SELECT 
  PredictSequence([SeqCluster_Model].[ProductCategory], 2) AS NextPurchases
FROM [SeqCluster_Model]
NATURAL PREDICTION JOIN
  (SELECT 'Sport' AS ProductCategory UNION
   SELECT 'Casual') AS t

/* R√âSULTAT:
Si historique = [Sport, Casual]
Pr√©dictions:
1. Sport (Prob: 0.45)      ‚Üê Retour au sport
2. Formal (Prob: 0.28)     ‚Üê Diversification
3. Boots (Prob: 0.15)

UTILISATION:
Email cibl√©: "D'apr√®s vos achats, vous pourriez aimer..."
*/
```

---

## üéØ CAS 6 : VALEUR CLIENT

### **Structure 6 : Linear Regression**

**Quand l'utiliser :**  
- Pr√©dire valeur continue (CLV, panier, etc.)
- Relations lin√©aires claires
- Besoins explicabilit√©

**Cr√©ation :**

```
Algorithm: Microsoft Linear Regression

Colonnes:
INPUT:
‚òë TenureMonths
‚òë TotalOrders
‚òë RecencyScore
‚òë FrequencyScore

PREDICTABLE:
‚òë TotalSpent (Continuous)

(Linear Regression = Neural Network avec 0 hidden nodes)
```

**Interpr√©ter les SCORES :**

```
Coefficient Analysis:
TotalOrders:    +‚Ç¨85 par commande    ‚≠ê‚≠ê‚≠ê (fort)
TenureMonths:   +‚Ç¨12 par mois       ‚≠ê‚≠ê
FrequencyScore: +‚Ç¨45 par point      ‚≠ê‚≠ê
RecencyScore:   -‚Ç¨8 par point       ‚≠ê (faible)

√âquation:
TotalSpent = 50 + (85 √ó Orders) + (12 √ó Tenure) + (45 √ó Frequency) - (8 √ó Recency)

R¬≤ = 0.82  (82% variance expliqu√©e) ‚Üí Bon mod√®le ‚úì
```

**Requ√™te DMX :**

```dmx
SELECT 
  t.CustomerKey,
  Predict([LR_Value_Model].[TotalSpent]) AS PredictedCLV,
  t.TotalSpent AS ActualSpent
FROM [LR_Value_Model]
PREDICTION JOIN ...

/* R√âSULTAT:
CustomerKey  PredictedCLV  ActualSpent  Diff
CUST-00001   ‚Ç¨1,250        ‚Ç¨1,180       +‚Ç¨70   (bon pr√©dicteur)
CUST-00002   ‚Ç¨680          ‚Ç¨720         -‚Ç¨40
CUST-00003   ‚Ç¨2,100        ‚Ç¨2,050       +‚Ç¨50

UTILISATION:
- Budgeter campagnes (cibler high CLV)
- Identifier clients sous-valoris√©s (Actual > Predicted)
- Scoring cr√©dit / limites
*/
```

---

## üéØ CAS 7 : CLASSIFICATION RAPIDE

### **Structure 7 : Na√Øve Bayes**

**Quand l'utiliser :**  
- Classification simple et rapide
- Features ind√©pendantes
- Besoin de vitesse plus que pr√©cision

**Cr√©ation :**

```
Algorithm: Microsoft Naive Bayes
(M√™mes colonnes que Decision Tree)

Param√®tres:
MAXIMUM_INPUT_ATTRIBUTES: 255
MAXIMUM_OUTPUT_ATTRIBUTES: 255
MINIMUM_DEPENDENCY_PROBABILITY: 0.5
```

**Interpr√©ter les SCORES :**

```
Attribute Profiles:

Given: RecencyScore = 1
P(Churn=1) = 0.92
P(Churn=0) = 0.08

Given: RecencyScore = 5
P(Churn=1) = 0.05
P(Churn=0) = 0.95

Attribute Characteristics (Churn=1):
RecencyScore=1:     92% (very strong)
FrequencyScore=1:   88%
MonetaryScore=1-2:  75%
AgeGroup=18-25:     62%
```

**Requ√™te DMX :**

```dmx
SELECT 
  t.CustomerKey,
  PredictProbability([NB_Model].[HasChurned], 1) AS ChurnProb,
  PredictProbability([NB_Model].[HasChurned], 0) AS ActiveProb
FROM [NB_Model]
PREDICTION JOIN ...

/* Plus rapide que Neural Network
Utiliser pour:
- Scoring temps r√©el (API)
- Batch tr√®s large (millions)
- Prototype rapide
*/
```

---

## üìä COMPARAISON FINALE

### **Accuracy Chart - Lift**

```
Tous mod√®les sur m√™me test set:

Algorithm            Lift @20%  Lift @50%  MAPE    Speed
Neural Network       4.2        3.1        12%     Slow
Logistic Regression  3.9        3.0        14%     Fast
Decision Tree        3.5        2.8        16%     Fast
Na√Øve Bayes         3.2        2.6        18%     Very Fast
Clustering          N/A        N/A        N/A     Medium

INTERPR√âTATION LIFT:
Lift 4.2 @20% = En ciblant top 20% des clients scor√©s,
on capture 4.2√ó plus de churn√©s que random
```

### **Quand utiliser quel algorithme ?**

```
BESOIN                          ALGORITHME
Comprendre causes               ‚Üí Decision Trees ‚≠ê
Probabilit√© pr√©cise             ‚Üí Logistic Regression / Neural Network ‚≠ê
Vitesse maximale                ‚Üí Na√Øve Bayes
Segmentation automatique        ‚Üí Clustering ‚≠ê
Produits li√©s                   ‚Üí Association Rules ‚≠ê
Pr√©visions temporelles          ‚Üí Time Series ‚≠ê
Parcours client                 ‚Üí Sequence Clustering
Pr√©dire valeur num√©rique        ‚Üí Linear Regression
Maximum pr√©cision (opaque ok)   ‚Üí Neural Network ‚≠ê
```

---

## ‚úÖ R√âCAPITULATIF

```
7 Structures cr√©√©es:
1. Churn (3 mod√®les: DT, LR, NN)
2. Clustering
3. Association Rules
4. Time Series
5. Sequence Clustering
6. Linear Regression
7. Na√Øve Bayes

TOUS process√©s et pr√™ts pour scoring!
```

**Prochaine √©tape :** MINING_5_Scoring_DMX.sql  
(Requ√™tes DMX compl√®tes + R√©int√©gration DW)

---

**üéØ Scores bien expliqu√©s, pas de blabla inutile!**